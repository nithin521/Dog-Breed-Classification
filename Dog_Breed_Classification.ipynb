{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6420aad6-3695-44b8-93b3-debc988776b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53de0781-ee23-431c-8f94-d5d3bdcf4685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 16464 files for training.\n",
      "Found 20580 files belonging to 120 classes.\n",
      "Using 4116 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "directory=os.getcwd()\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),  # Flip the image horizontally\n",
    "    layers.RandomRotation(0.2),  # Randomly rotate the image by 20%\n",
    "    layers.RandomZoom(0.2),  # Randomly zoom into the image by 20%\n",
    "    layers.RandomContrast(0.2),  # Adjust contrast by up to 20%\n",
    "    layers.RandomBrightness(0.2),  # Randomly change brightness by 20%\n",
    "])\n",
    "\n",
    "train_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{directory}/dogs_breed/images\",\n",
    "    labels=\"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(260,260),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{directory}/dogs_breed/images\",\n",
    "    labels=\"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(260,260),\n",
    "    batch_size=32\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bafee1a-144f-4938-bbf7-7a80d7a32e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_labels=train_dataset.class_names\n",
    "class_count=[0]*len(class_labels)\n",
    "\n",
    "for _,labels in train_dataset.unbatch():\n",
    "    class_index=tf.argmax(labels).numpy()\n",
    "    class_count[class_index]+=1\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",  # Use the 'balanced' strategy to handle imbalance\n",
    "    classes=np.arange(len(class_labels)),  # Classes as integers [0, 1, 2, ...]\n",
    "    y=np.concatenate([[i] * count for i, count in enumerate(class_count)])  # Flattened class distribution\n",
    ")\n",
    "# print(class_weights,len(class_weights))\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)} \n",
    "\n",
    "# classes=np.arange(len(class_labels)),  # Classes as integers [0, 1, 2, ...]\n",
    "# y=np.concatenate([[i] * count for i, count in enumerate(class_count)])\n",
    "# print(y,len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cad81e-f797-473a-b783-aa1632f73574",
   "metadata": {},
   "source": [
    "<h2>Training with combined model (Resnet and EfficientNetB1 )</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b55e71c-c21c-419e-b76b-44d1c553da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2244s\u001b[0m 4s/step - accuracy: 0.4976 - loss: 2.2025 - val_accuracy: 0.8506 - val_loss: 0.4484\n",
      "Epoch 2/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2210s\u001b[0m 4s/step - accuracy: 0.8397 - loss: 0.5120 - val_accuracy: 0.8550 - val_loss: 0.4142\n",
      "Epoch 3/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2215s\u001b[0m 4s/step - accuracy: 0.8717 - loss: 0.3991 - val_accuracy: 0.8627 - val_loss: 0.4127\n",
      "Epoch 4/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2254s\u001b[0m 4s/step - accuracy: 0.8946 - loss: 0.3233 - val_accuracy: 0.8642 - val_loss: 0.4341\n",
      "Epoch 5/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2272s\u001b[0m 4s/step - accuracy: 0.9048 - loss: 0.2907 - val_accuracy: 0.8756 - val_loss: 0.4101\n",
      "Epoch 6/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2225s\u001b[0m 4s/step - accuracy: 0.9198 - loss: 0.2365 - val_accuracy: 0.8664 - val_loss: 0.4459\n",
      "Epoch 7/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 4s/step - accuracy: 0.9254 - loss: 0.2217 - val_accuracy: 0.8737 - val_loss: 0.4349\n",
      "Epoch 8/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2267s\u001b[0m 4s/step - accuracy: 0.9409 - loss: 0.1718 - val_accuracy: 0.8761 - val_loss: 0.4509\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB2, ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Step 1: Define the input shape\n",
    "input_shape = (260, 260, 3)  # Match EfficientNetB1's required input size\n",
    "input_tensor = Input(shape=input_shape)\n",
    "\n",
    "# Step 2: Load ResNet18 (simulate with ResNet50 and a subset of layers)\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "for layer in resnet_base.layers[:-10]:  # Freeze all but the last 10 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Step 3: Load EfficientNetB1\n",
    "efficientnet_base = EfficientNetB2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "efficientnet_base.trainable = False  # Freeze EfficientNetB1 base\n",
    "\n",
    "# Step 4: Extract features from both models\n",
    "resnet_features = GlobalAveragePooling2D()(resnet_base.output)\n",
    "efficientnet_features = GlobalAveragePooling2D()(efficientnet_base.output)\n",
    "\n",
    "# Step 5: Concatenate features\n",
    "combined_features = Concatenate()([resnet_features, efficientnet_features])\n",
    "\n",
    "# Step 6: Add custom fully connected layers\n",
    "x = Dense(1024, activation='relu')(combined_features)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "output = Dense(120, activation='softmax')(x)  # Adjust for 120 classes\n",
    "\n",
    "# Step 7: Create the final model\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "# Step 8: Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 9: Print model summary\n",
    "# model.summary()\n",
    "\n",
    "# Step 10: Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights_dict,  # Optional: Use for imbalanced datasets\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 11: Save the model\n",
    "model.save(\"resnet18_efficientnetb2_combined.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3b4302-402e-4af4-9ba1-93986ce28174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Predicted Class: Doberman\n",
      "Confidence: 99.99%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = tf.keras.models.load_model(\"resnet18_efficientnetb1_combined.keras\")  # Replace with your model file path\n",
    "\n",
    "\n",
    "def preprocess_image(img_path, target_size=(240, 240)):\n",
    "    \"\"\"\n",
    "    Preprocess the image for prediction.\n",
    "    Args:\n",
    "    - img_path (str): Path to the image file.\n",
    "    - target_size (tuple): Target size of the image for the model.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Preprocessed image ready for prediction.\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=target_size)  # Load the image and resize\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)  # Normalize as per EfficientNet\n",
    "    return img_array\n",
    "\n",
    "# Step 4: Predict the class\n",
    "def predict_image(img_path):\n",
    "    \"\"\"\n",
    "    Predict the class of an image using the trained model.\n",
    "    Args:\n",
    "    - img_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Predicted class label.\n",
    "    - float: Confidence of the prediction.\n",
    "    \"\"\"\n",
    "    img_array = preprocess_image(img_path, target_size=(240, 240))  # Ensure input matches model input size\n",
    "    predictions = model.predict(img_array)  # Get probabilities for each class\n",
    "    predicted_index = np.argmax(predictions, axis=1)[0]  # Get the index of the highest probability\n",
    "    predicted_label = class_labels[predicted_index]  # Get the class label\n",
    "    confidence = predictions[0][predicted_index] * 100  # Get the confidence score\n",
    "\n",
    "    return predicted_label, confidence\n",
    "\n",
    "# Example usage\n",
    "img_path = \"doberman.jpg\"  \n",
    "predicted_label, confidence = predict_image(img_path)\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")\n",
    "print(f\"Confidence: {confidence:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a640e83-a789-4ef1-8da1-a2a0d71daa09",
   "metadata": {},
   "source": [
    "<h2>Training with Resnet50 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d5f350-1bc1-476e-aef9-b5f6278845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model=tf.keras.applications.ResNet50(\n",
    "#     weights=\"imagenet\",\n",
    "#     include_top=False,\n",
    "#     input_shape=(224,224,3)\n",
    "# )\n",
    "# base_model.trainable=False\n",
    "\n",
    "# model=tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(256,activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(120,activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0007),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "# history=model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=validation_dataset,\n",
    "#     epochs=10,\n",
    "#     class_weight=class_weights_dict, \n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True),\n",
    "#         tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.save(\"dog_breed_classifier4.h5\") \n",
    "\n",
    "# base_model.trainable = True\n",
    "# for layer in base_model.layers[:-5]: \n",
    "#     layer.trainable = False\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history_finetuned = model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=validation_dataset,\n",
    "#     epochs=5,\n",
    "#     class_weight=class_weights_dict, \n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
    "#         tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "#     ]\n",
    "# )\n",
    "# model.save(\"dog_breed_classifier3.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0113987-ac6d-4c6a-a2dc-e21c0d18c3bd",
   "metadata": {},
   "source": [
    "<h2>Predicting With Resnet 50</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ae808d-51f9-4353-a629-dfea6d85d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model=load_model(\"dog_breed_classifier4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bd8790-890c-48d9-8ef4-f279d52d07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "\n",
    "# img=image.load_img(\"african_dog.jpg\",target_size=(224,224))\n",
    "# img_array=image.img_to_array(img)\n",
    "# img_array=np.expand_dims(img_array,axis=0)\n",
    "# img_array/=255.0\n",
    "\n",
    "# predictions=model.predict(img_array)\n",
    "# predicted_index = np.argmax(predictions, axis=1)\n",
    "# predicted_index1 = np.argmin(predictions, axis=1)\n",
    "# print(predictions,predicted_index,type(predictions),predicted_index1)\n",
    "\n",
    "\n",
    "# # for i in range(len(class_labels)):\n",
    "# #     print(f\"{i} . {class_labels[i]}\")\n",
    "# predicted_label = class_labels[predicted_index[0]]\n",
    "# predicted_label1 = class_labels[predicted_index1[0]]\n",
    "# print(predicted_label,predicted_label1)\n",
    "# # confidence = predictions[0][predicted_index] * 100\n",
    "\n",
    "# # print(f\"Predicted class: {predicted_label} (confidence: {confidence:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218eca5-c6f8-4298-8589-7cc2d7a900c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
